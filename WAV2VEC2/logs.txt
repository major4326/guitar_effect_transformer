Step: 1, {'loss': 0.6902, 'learning_rate': 2.9e-06, 'epoch': 0.03}
Step: 2, {'loss': 0.691, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.07}
Step: 3, {'loss': 0.6908, 'learning_rate': 2.7e-06, 'epoch': 0.1}
Step: 4, {'loss': 0.6875, 'learning_rate': 2.6e-06, 'epoch': 0.13}
Step: 5, {'loss': 0.6852, 'learning_rate': 2.5e-06, 'epoch': 0.17}
Step: 6, {'loss': 0.6876, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.2}
Step: 7, {'loss': 0.6854, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.23}
Step: 8, {'loss': 0.6874, 'learning_rate': 2.1999999999999997e-06, 'epoch': 0.27}
Step: 9, {'loss': 0.6853, 'learning_rate': 2.1e-06, 'epoch': 0.3}
Step: 10, {'loss': 0.6864, 'learning_rate': 2e-06, 'epoch': 0.33}
Step: 11, {'loss': 0.6838, 'learning_rate': 1.9e-06, 'epoch': 0.37}
Step: 12, {'loss': 0.6834, 'learning_rate': 1.8e-06, 'epoch': 0.4}
Step: 13, {'loss': 0.6848, 'learning_rate': 1.7e-06, 'epoch': 0.43}
Step: 14, {'loss': 0.6824, 'learning_rate': 1.6e-06, 'epoch': 0.47}
Step: 15, {'loss': 0.679, 'learning_rate': 1.5e-06, 'epoch': 0.5}
Step: 16, {'loss': 0.6821, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.53}
Step: 17, {'loss': 0.6829, 'learning_rate': 1.3e-06, 'epoch': 0.57}
Step: 18, {'loss': 0.6825, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.6}
Step: 19, {'loss': 0.6811, 'learning_rate': 1.0999999999999998e-06, 'epoch': 0.63}
Step: 20, {'loss': 0.6817, 'learning_rate': 1e-06, 'epoch': 0.67}
Step: 21, {'loss': 0.6782, 'learning_rate': 9e-07, 'epoch': 0.7}
Step: 22, {'loss': 0.6823, 'learning_rate': 8e-07, 'epoch': 0.73}
Step: 23, {'loss': 0.6768, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.77}
Step: 24, {'loss': 0.6794, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.8}
Step: 25, {'loss': 0.6788, 'learning_rate': 5e-07, 'epoch': 0.83}
Step: 26, {'loss': 0.6773, 'learning_rate': 4e-07, 'epoch': 0.87}
Step: 27, {'loss': 0.6807, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.9}
Step: 28, {'loss': 0.6803, 'learning_rate': 2e-07, 'epoch': 0.93}
Step: 29, {'loss': 0.6806, 'learning_rate': 1e-07, 'epoch': 0.97}
Step: 30, {'loss': 0.6782, 'learning_rate': 0.0, 'epoch': 1.0}
Step: 30, {'train_runtime': 42.5228, 'train_samples_per_second': 10.583, 'train_steps_per_second': 0.706, 'total_flos': 2.0429693424e+16, 'train_loss': 0.6831015527248383, 'epoch': 1.0}
Step: 30, {'eval_loss': 0.6781771779060364, 'eval_accuracy': 0.0, 'eval_f1': 0.4678832116788321, 'eval_runtime': 5.5485, 'eval_samples_per_second': 54.068, 'eval_steps_per_second': 6.849, 'epoch': 1.0}
Step: 1, {'loss': 0.6913, 'learning_rate': 2.9e-06, 'epoch': 0.03}
Step: 2, {'loss': 0.6907, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.07}
Step: 3, {'loss': 0.6903, 'learning_rate': 2.7e-06, 'epoch': 0.1}
Step: 4, {'loss': 0.687, 'learning_rate': 2.6e-06, 'epoch': 0.13}
Step: 5, {'loss': 0.6874, 'learning_rate': 2.5e-06, 'epoch': 0.17}
Step: 6, {'loss': 0.687, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.2}
Step: 7, {'loss': 0.6879, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.23}
Step: 8, {'loss': 0.6893, 'learning_rate': 2.1999999999999997e-06, 'epoch': 0.27}
Step: 9, {'loss': 0.6852, 'learning_rate': 2.1e-06, 'epoch': 0.3}
Step: 10, {'loss': 0.6872, 'learning_rate': 2e-06, 'epoch': 0.33}
Step: 11, {'loss': 0.6874, 'learning_rate': 1.9e-06, 'epoch': 0.37}
Step: 12, {'loss': 0.6876, 'learning_rate': 1.8e-06, 'epoch': 0.4}
Step: 13, {'loss': 0.6838, 'learning_rate': 1.7e-06, 'epoch': 0.43}
Step: 14, {'loss': 0.682, 'learning_rate': 1.6e-06, 'epoch': 0.47}
Step: 15, {'loss': 0.6816, 'learning_rate': 1.5e-06, 'epoch': 0.5}
Step: 16, {'loss': 0.6855, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.53}
Step: 17, {'loss': 0.6846, 'learning_rate': 1.3e-06, 'epoch': 0.57}
Step: 18, {'loss': 0.6828, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.6}
Step: 19, {'loss': 0.6807, 'learning_rate': 1.0999999999999998e-06, 'epoch': 0.63}
Step: 20, {'loss': 0.679, 'learning_rate': 1e-06, 'epoch': 0.67}
Step: 21, {'loss': 0.6817, 'learning_rate': 9e-07, 'epoch': 0.7}
Step: 22, {'loss': 0.6838, 'learning_rate': 8e-07, 'epoch': 0.73}
Step: 23, {'loss': 0.6791, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.77}
Step: 24, {'loss': 0.68, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.8}
Step: 25, {'loss': 0.6803, 'learning_rate': 5e-07, 'epoch': 0.83}
Step: 26, {'loss': 0.6819, 'learning_rate': 4e-07, 'epoch': 0.87}
Step: 27, {'loss': 0.6821, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.9}
Step: 28, {'loss': 0.6795, 'learning_rate': 2e-07, 'epoch': 0.93}
Step: 29, {'loss': 0.6827, 'learning_rate': 1e-07, 'epoch': 0.97}
Step: 30, {'loss': 0.6775, 'learning_rate': 0.0, 'epoch': 1.0}
Step: 30, {'train_runtime': 42.5756, 'train_samples_per_second': 10.569, 'train_steps_per_second': 0.705, 'total_flos': 2.0429693424e+16, 'train_loss': 0.6842303176720937, 'epoch': 1.0}
Step: 30, {'eval_loss': 0.6789464950561523, 'eval_accuracy': 0.0, 'eval_f1': 0.33614232209737827, 'eval_runtime': 5.6968, 'eval_samples_per_second': 52.662, 'eval_steps_per_second': 6.67, 'epoch': 1.0}
Step: 1, {'loss': 0.6932, 'learning_rate': 2.9957203994293868e-06, 'epoch': 0.0}
Step: 2, {'loss': 0.6933, 'learning_rate': 2.9914407988587735e-06, 'epoch': 0.0}
Step: 3, {'loss': 0.6912, 'learning_rate': 2.9871611982881598e-06, 'epoch': 0.0}
Step: 4, {'loss': 0.6921, 'learning_rate': 2.9828815977175465e-06, 'epoch': 0.01}
Step: 5, {'loss': 0.6913, 'learning_rate': 2.978601997146933e-06, 'epoch': 0.01}
Step: 6, {'loss': 0.6906, 'learning_rate': 2.97432239657632e-06, 'epoch': 0.01}
Step: 7, {'loss': 0.6912, 'learning_rate': 2.9700427960057062e-06, 'epoch': 0.01}
Step: 8, {'loss': 0.6897, 'learning_rate': 2.965763195435093e-06, 'epoch': 0.01}
Step: 9, {'loss': 0.6868, 'learning_rate': 2.9614835948644792e-06, 'epoch': 0.01}
Step: 10, {'loss': 0.6902, 'learning_rate': 2.957203994293866e-06, 'epoch': 0.01}
